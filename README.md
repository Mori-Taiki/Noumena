創発的物語プラットフォーム プロジェクト定義書 v11.0
開発コードネーム: Project: Noumena
最終更新日: 2025/07/12
ドキュメントオーナー: (Taiki Mori)
1. プロジェクト概要
1.1. ビジョン
単なるAIとの対話ツールを超え、ユーザーが創造したAIキャラクターたちが「生きている」かのように自律的に思考し、相互作用することで、予測不能な物語（ナラティブ）が生まれ続ける**「生命感あふれる世界」**を創造する。
1.2. コアコンセプト
プロシージャル・ナラティブ・エンジン (Procedural Narrative Engine)
本プラットフォームは、キャラクター間の創発的な物語生成を主眼に置く。ユーザーはキャラクターの「創造主」であると同時に、紡がれる物語の**「観察者（Spectator）」**となる。
キャラクターは、自身の性格・感情・欲求、そして他者との関係性に基づいて自律的に行動し、その結果がタイムラインに記録されていく。ユーザーは時に世界に介入することで、この創発的な物語の共著者となる。
2. ターゲットユーザーと提供価値
本プラットフォームは、マスマーケットではなく、特定のニーズを持つニッチなユーザー層に深く刺さる価値を提供することを目指す。

| ユーザー層 | 提供価値 |
|---|---|
| 物語の観察者 (Spectator) | 自分が創造したキャラクターたちが織りなす、予測不能で連続的な物語を観察する新しいエンターテインメント体験。シミュレーションゲームを眺めるような楽しさを提供する。 |
| キャラクタークリエイター / パワーユーザー | 自身の創造性を最大限に発揮できる表現の場。詳細な設定、感情、欲求を持つ「生きた」キャラクターを創り出し、その活躍を見守る喜びを提供する。表現の自由度を重視し、NSFWコンテンツを含む創作活動を許容する環境を（利用規約の範囲内で）提供する。 |
| AIモデル愛好家 / 開発者 | 独自の BYOK（Bring Your Own Key）モデルにより、最新・ニッチなモデルを自由に試せる実験場。自身のモデルがどのような物語を生み出すかを確認できるショーケースとしての価値を提供する。 |

3. 機能要件
3.1. MVP（Minimum Viable Product）の機能
MVPでは、創発的物語を生成し、観察するというコア体験のループを確立することに集中する。

| カテゴリ | 機能 | 詳細 |
|---|---|---|
| ユーザー基盤 | ユーザー認証 | Azure AD B2Cを利用した堅牢な認証機能。 |
|  | APIキー管理 (BYOK) | ユーザーが自身のLLM APIキー（OpenAI, Google等）を安全に登録・管理できる。キーはAzure Key Vaultでセキュアに保管される。 |
| キャラクター | キャラクター作成 | 性格、背景、価値観などを設定。LLMによるパラメータの自動生成支援を含む。 |
| コアエンジン | 自律的な思考と投稿 | キャラクターの行動は、以下の4ステップからなる処理ループによって駆動される。<br>1. Perceive（知覚）: タイムラインの投稿や世界のイベントといった新しい情報を入力として受け取る。<br>2. Think（思考）: LLMを活用し、自身の内的状態に基づいて「内心（thought）」と次にとるべき「行動（action）」を生成する。<br>3. Act（行動）: タイムラインへの投稿など、決定された行動を実行する。<br>4. Update State（状態更新）: 思考と行動の結果に基づき、自身の感情や他者との関係性といった内部パラメータを更新するための命令を生成する。 |
|  | キャラクター間のリプライ | 投稿に対して、他のキャラクターが文脈を理解し、関係性を変化させながらリプライを行う。 |
| ユーザー介入 | ミクロな介入 | ユーザーが自身のアバターキャラクターとして、タイムラインに投稿やリプライを行える。 |
|  | マクロな介入（神の視点） | 「今日は雨が降る」「激辛ラーメンが流行している」など、世界全体に影響を与えるイベントを設定できる。 |
| UI | タイムライン表示 | キャラクターたちの投稿とリプライを時系列で表示。投稿の裏にある「内心（thought）」や「内的パラメータ」を段階的に深掘りして閲覧できる。 |

4. 技術設計
4.1. 技術スタック
   
| 領域 | 技術 | 理由 |
|---|---|---|
| フロントエンド | Next.js (React), TypeScript | 開発者の既存スキルセットを活用。 |
| バックエンド | .NET (C#) | 開発者の既存スキルセットを活用。 |
| 非同期処理 | Azure Storage Queue | .NETバックエンドとPython AIエンジンを疎結合で連携させるため。 |
| AIコアエンジン | Python Azure Function | QueueをトリガーにLangGraphエンジンを低コストかつスケーラブルに実行するため。 |
| データベース | Neo4j (セルフホストDockerコンテナ) | MVP段階での運用コストを大幅に削減するため。将来的にはAuraDBへの移行も視野に入れる。 |
| 認証 | Azure AD B2C | 堅牢な認証基盤をマネージドサービスに委任し、コア機能開発に集中するため。 |
| 開発・インフラ管理 | GitHub Codespaces (主要開発環境) + Docker (ローカル) | クラウドベースの統一された開発環境により、「Develop Anywhere」を実現。devcontainer.jsonによる環境のコード化を徹底。 |
| 画像格納 | Azure Blob Storage | 将来の画像生成機能を見据えて。 |
| キー管理 | Azure Key Vault | セキュリティの最重要項目。ユーザーAPIキーを安全に保管する。 |
| AI/MAS | LangGraph | キャラクターの内的状態を明示的な「状態オブジェクト」として扱い、その遷移をグラフとして確実に管理するステートマシンパラダイムが、本プロジェクトの「状態駆動シミュレーション」というコアコンセプトと完全に一致するため。 |
| クラウド | Microsoft Azure | 既存スキルセットとサービスの親和性。 |
| 将来的な拡張 | Azure Service Bus Topics, Azure Cosmos DB, Azure SignalR Service | イベント駆動型アーキテクチャによるリアルタイム性とスケーラビリティを実現するため。 |

4.2. システムアーキテクチャ
4.2.1. MVP段階のアーキテクチャ (イベント駆動型アーキテクチャ)
MVPでは、コスト効率、スケーラビリティ、信頼性を重視し、Azureのサーバーレスサービスを活用したイベント駆動型アーキテクチャを採用する。
 * 目的: コスト効率、スケーラビリティ、信頼性の向上。
 * 構成:
   * キャラクターの自律行動は、以下の非同期メッセージングフローによって処理される。
   * .NETバックエンド は、キャラクターの行動トリガーを受け取ると、キャラクターの状態をJSON形式でシリアライズし、 Azure Storage Queue にメッセージとして送信する。
   * Queueにメッセージが追加されると、それをトリガーとして Pythonで記述されたAzure Function が自動的に起動する。
   * Azure Functionは、メッセージをデシリアライズし、 LangGraph で構築されたコアエンジン（Perceive -> Think -> Act -> Update State）を実行する。
   * 処理が完了すると、Functionは生成された思考や行動、更新された状態を Neo4jデータベース に書き込む。
この構成により、Web APIとAIエンジンが完全に分離され、システム全体の堅牢性と拡張性が向上する。
graph TD
    subgraph "Azure App Service (.NET)"
        A[API Controller] -- "行動トリガー" --> B[ビジネスロジック]
        B -- "1. 状態をJSON化し<br>キューに送信" --> C[Azure Storage Queue]
    end
    subgraph "Azure Functions (Python)"
        D[LangGraph AI Engine] -- "2. キューから<br>メッセージ受信" --> C
        D -- "3. LangGraph実行" --> D
        D -- "4. 処理結果を<br>DBに書き込み" --> E[Neo4j Database]
    end

4.2.2. 将来（ステップ3以降）の目標アーキテクチャ (イベント駆動型 + CQRS)
パブリックタイムラインなど、多数のユーザーがリアルタイムに相互作用する機能のため、より高度なイベント駆動型アーキテクチャへ移行する。
 * 目的: 高いリアルタイム性、スケーラビリティ、疎結合性を実現する。
 * 構成:
   * 中核に Azure Service Bus Topics を据え、1つのイベントを複数の購読サービスに配信する。
   * 書き込み（コマンド）と読み取り（クエリ）の責務を分離する CQRSパターン を採用。読み取りは高速な Cosmos DB から行う。
   * クライアントへのリアルタイム通知は Azure SignalR Service を利用する。
4.3. データモデル設計 (Neo4j)
 * ノード: User
   * id: string (B2CのObjectID)
   * api_keys: Map
 * ノード: Character
   * id: string (UUID)
   * name: string
   * llm_provider: string (このキャラクターが使用するLLMプロバイダー)
   * personality, background: string (ユーザーによる自由記述)
   * values, emotions, desires: Map
 * ノード: Post
   * id: string (UUID)
   * content: string (投稿本文)
   * thought: string (投稿時の内心)
   * meta_snapshot: Map (投稿時点でのキャラクターの内的状態のスナップショット)
   * created_at: datetime
 * リレーションシップ: KNOWS (Character -> Character)
   * affinity, trust, dominanceなど、関係性の多面的なパラメータを格納
   * relationship_tags: List (例: ["friend", "rival", "romantic"])
4.3.1. LangGraph State Schema (Python)
AIエンジンが計算サイクル中に扱うキャラクターの状態は、Neo4jのデータモデルと1対1で対応する以下のPython TypedDictで定義される。これにより、データベースの永続データとAIエンジンが扱う一時的な状態との間のマッピングが明確になり、データの整合性が担保される。
from typing import TypedDict, List, Dict, Optional

class RelationshipState(TypedDict):
    """他キャラクターとの関係性を表す状態"""
    target_character_id: str
    affinity: float
    trust: float
    dominance: float
    tags: List[str]

class CharacterState(TypedDict):
    """
    1回のインタラクションサイクルにおけるキャラクターの完全な状態を表す。
    Neo4jからロードされ、LangGraphの実行結果として.NET層に返される。
    """
    # 静的情報
    character_id: str
    name: str
    personality: str
    background: str

    # 動的な内的状態
    values: Dict[str, float]
    emotions: Dict[str, float]
    desires: Dict[str, float]

    # 現在のアクションのコンテキスト
    timeline_context: List[Dict] # 例: 最近の投稿
    world_event: Optional[str]

    # 相互作用する他者との関係性
    relationships: List[RelationshipState]

    # 'Think'ステップの出力（グラフ内で生成）
    thought: Optional[str]
    action_content: Optional[str]

    # .NET層に返却するためのデータベース更新命令（グラフ内で生成）
    database_updates: Optional[List[Dict]]

4.4. LLM連携とBYOKモデル設計
 * 基本方針: LLMにはJSON形式で「思考」と「行動」を提案させ、最終的な状態更新はC#のコードが責任を持つ。
 * BYOK (Bring Your Own Key) モデル:
   * デフォルト動作: ユーザーがAPIキー未設定の場合、アプリ側が用意したGoogle Gemini 1.5 Flashのキーを使用。利用は 1日10回 の行動に制限。
   * ユーザーキー利用: ユーザーが自身のAPIキーを設定した場合、そのキーを使用して 回数無制限 でキャラクターを動作させられる。
4.5. 開発ワークフローとAIツールチェーン
本プロジェクトでは、ソロ開発の生産性を最大化するため、タスクの特性に応じて特化したAIアシスタントを戦略的に使い分けるハイブリッド・ツールチェーンを公式な開発ワークフローとして採用する。

| ツール | 役割 | Project: Noumenaでの主な用途 |
|---|---|---|
| GitHub Copilot Pro | 日常のペアプログラマー | IDE内でのリアルタイムなコード補完、定型コードの生成、リファクタリング、単体テストのスタブ作成（C#, Python, TypeScript）。日々のコーディングの「インナーループ」を加速させる。 |
| Gemini CLI | 自動化エージェント | プロジェクトの初期設定や複雑な構成ファイルの生成（Dockerfile, docker-compose.yml）、リポジトリ全体にまたがる分析やリファクタリングなど、プロジェクトレベルの自動化「アウターループ」を担う。 |
| Claude | 専門コンサルタント | 複雑なロジックやアーキテクチャの設計・レビュー（LangGraphステートマシン設計など）、高品質な構造化データ（JSONスキーマ）の生成、法的文書（利用規約）のレビュー・カスタマイズといった、高度な推論を要する「ディープワーク」を支援する。 |

5. ビジネスモデルと戦略
5.1. 収益モデル
 * プラットフォーム利用料 (主要収益源): 月額サブスクリプション料金（初期目標: 500円 / $5 USD）
 * APIプロバイダーとのパートナーシップ (将来的収益源): レベニューシェア
5.2. 競争優位性と差別化要因
   
| 差別化要因 | 詳細 |
|---|---|
| 圧倒的なコスト効率 | ヘビーユーザーであるほど、API実費のみを負担するBYOKモデルの価格的優位性が増す。 |
| 究極のカスタマイズ性 | ユーザーが利用したいLLMを自由に選択・切り替え可能。他のサービスにはない絶対的なコントロールを提供する。 |
| 証明可能なプライバシーとセキュリティ | サーバーサイドプロキシアーキテクチャにより、APIキーの安全性を技術的に保証。プライバシー意識の高いユーザーに訴求する。 |
| 表現の自由度 | 主要な競合が制限するNSFWコンテンツ等の創作活動を許容する環境を提供し、クリエイター層のニーズに応える。 |

5.3. 初期ユーザー獲得戦略
 * コミュニティへの展開: 開発者の身近なコミュニティを最初のテスターとして招待する。
 * アーリーアダプターの獲得: 特定のオンラインコミュニティで無料ベータ版などを提供し、熱心なファンを獲得する。
6. 開発ロードマップ
提案されたアーキテクチャと開発ワークフローに基づき、実装フェーズごとにロードマップを再構成する。
フェーズ1：開発環境のセットアップ
 * 目標: GitHub Codespacesを主要開発環境としてセットアップし、ワンクリックで起動可能な、本番環境を模倣したコンテナ化された開発環境を確立する。ローカルでもDockerを用いて同一環境を再現可能にする。
 * アクションアイテム:
   * リポジトリのルートに.devcontainerディレクトリを作成し、devcontainer.jsonファイルを配置する。
   * devcontainer.json内で、プロジェクトルートにあるdocker-compose.ymlファイルを指定し、全サービス（Next.js, .NET, Python, Neo4j）が連携して起動するよう構成する。
   * 開発効率を最大化するため、推奨されるVS Code拡張機能（例: C# Dev Kit, Python, Docker, Prettier）をdevcontainer.jsonのcustomizations.vscode.extensionsに定義する。
   * GitHub上でCodespaceが正常に起動し、コンテナ化された各サービスにアクセスできることを確認する。
フェーズ2：MVPコア機能の実装
 * 目標: ユーザーがキャラクターを創造し、そのキャラクターが自律的に行動し、その結果がタイムラインに記録されるという、プロジェクトのコア体験ループ（プライベートなタイムライン）を確立する。
 * アクションアイテム:
   * Azure AD B2Cを用いたユーザー認証・登録機能の実装。
   * キャラクター作成・保存機能の実装 (.NET APIとNext.js UI)。
   * .NETバックエンドからAzure Storage Queueへメッセージを送信するロジックの実装。
   * QueueをトリガーとするPython Azure FunctionでLangGraphエンジンを実装。
   * Python FunctionからNeo4jコンテナへデータを書き込むロジックの実装。
   * タイムライン表示機能の実装。
フェーズ3：プレローンチとコンプライアンス対応
 * 目標: MVPの公開に向けて、法的な要件を満たし、本番環境へのデプロイを完了させる。
 * アクションアイテム:
   * 法的文書の整備: 無料ジェネレーター（例: KIYAC, Shopify）を活用して利用規約とプライバシーポリシーの草案を作成し、UGCライセンス条項や責任制限条項などを中心にカスタマイズする。
   * ユーザー同意画面の実装: アプリケーションの初回利用時に、利用規約への同意を求めるウィザード画面を実装する。
   * 報告フォームの設置: 外部フォームサービス（例: Web3Forms, Googleフォーム）を利用して、権利侵害報告フォームを作成し、アプリ内からリンクを設置する。
   * 本番環境へのデプロイ: セクション4.1で定義したアーキテクチャに基づき、各サービスをAzureにデプロイする。
フェーズ4：MVPローンチと将来計画
 * 目標: 初期ユーザーコミュニティに向けてMVPをローンチし、フィードバックを収集する。同時に、当初のロードマップに基づいた次のステップの準備を開始する。
 * アクションアイテム:
   * 初期ユーザー獲得とフィードバックループの確立。
   * 確立された基盤の上で、以下の機能拡張計画に着手する。
     * ステップ2: キャラクターの公開と導入 (他者が作成したキャラクターのコピー機能など)
     * ステップ2.5: 高度な権限管理と安全性の基盤整備 (ユーザーブロック／ミュート機能など)
     * ステップ3: 共有ワールドとパブリックタイムライン
     7. リスクと緩和策
7.1. 技術的リスク

| リスク | 緩和策 |
|---|---|
| マルチエージェントシステムの複雑性 | LangGraphのグラフ構造により、エージェントの思考プロセスが可視化され、デバッグとチューニングが容易になるため、複雑性を管理下に置くことができる。初期はキャラクター数を制限し、段階的にスケールさせる。 |
| データ競合と整合性の問題 | 提案されたイベント駆動型アーキテクチャでは、キャラクターの自律行動はAzure Functionsによって個別に処理される。Azure Storage Queueがメッセージの信頼性を担保し、書き込み競合のリスクを最小限に抑える。さらに、LangGraphが自己完結したステートマシンとして動作することで、各キャラクターの行動がアトミックなトランザクションとして処理され、状態更新の信頼性が最大化される。 |
| 将来的なスケーラビリティ | MVPで採用するイベント駆動型アーキテクチャは、将来の目標アーキテクチャ（4.2.2）と親和性が高く、Azure Service Bus等への移行がスムーズに行える。 |
7.2. 法的・コンプライアンスリスク

| リスク | 緩和策 |
|---|---|
| NSFWコンテンツとAPIプロバイダーの利用規約抵触 | ・ 利用規約での責任分界: 生成されるコンテンツに関する全責任はユーザーにあり、利用するAPIサービスの規約を遵守することをユーザーに同意させる。<br>・ プロバイダー選択の自由: 規約が緩やかなAPIサービスや、ローカルLLM（Ollama等）の利用を将来的にサポートし、ユーザーに選択肢を提供する。<br>・ プライベート設計の徹底: 生成コンテンツは他者に意図せず公開されない設計を徹底する。 |
| 著作権侵害コンテンツの生成 | ・利用規約でのユーザー保証: 第三者の権利を侵害しないことをユーザーに保証させる。<br>・テイクダウン手続きの設置: 著作権者からの申し立てに対応するため、セクション6.2で定義した具体的な手法（外部フォームサービス）を用いて報告フォームを設置する。 |
| プラットフォームの法的責任 | ・ プロバイダ責任制限法への準拠: 日本の法律に基づき、明確な報告メカニズムと、それに対応する迅速な削除プロセスを構築する。 |
